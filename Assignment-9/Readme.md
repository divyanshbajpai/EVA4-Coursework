# Assignment-9

- Epoch: 25
- Val_Acc: 90.32 %
- ResNet18 on Cifar10
- Augmentation Strategy: Random Horizontal Flip on Train data, Normalization on test and train

## Graph

![Acc and Loss](https://github.com/divyanshbajpai/EVA4-Coursework/blob/master/Assignment-9/s9.png?raw=true)

# Logs

0%|          | 0/391 [00:00<?, ?it/s]EPOCH: 0
Loss=1.269968 Batch_id=390 Accuracy=53.86: 100%|██████████| 391/391 [00:54<00:00,  7.20it/s]
  0%|          | 0/391 [00:00<?, ?it/s]
Test set: Average loss: 1.034489, Accuracy: 6331/10000 (63.31%)

EPOCH: 1
Loss=0.761081 Batch_id=390 Accuracy=73.29: 100%|██████████| 391/391 [00:55<00:00,  7.05it/s]
  0%|          | 0/391 [00:00<?, ?it/s]
Test set: Average loss: 1.015358, Accuracy: 6673/10000 (66.73%)

EPOCH: 2
Loss=0.595582 Batch_id=390 Accuracy=79.32: 100%|██████████| 391/391 [00:56<00:00,  6.96it/s]
  0%|          | 0/391 [00:00<?, ?it/s]
Test set: Average loss: 0.722465, Accuracy: 7507/10000 (75.07%)

EPOCH: 3
Loss=0.508290 Batch_id=390 Accuracy=82.39: 100%|██████████| 391/391 [00:56<00:00,  6.94it/s]
  0%|          | 0/391 [00:00<?, ?it/s]
Test set: Average loss: 0.594480, Accuracy: 7925/10000 (79.25%)

EPOCH: 4
Loss=0.447544 Batch_id=390 Accuracy=84.65: 100%|██████████| 391/391 [00:56<00:00,  6.95it/s]
  0%|          | 0/391 [00:00<?, ?it/s]
Test set: Average loss: 0.688105, Accuracy: 7681/10000 (76.81%)

EPOCH: 5
Loss=0.416667 Batch_id=390 Accuracy=85.78: 100%|██████████| 391/391 [00:56<00:00,  6.95it/s]
  0%|          | 0/391 [00:00<?, ?it/s]
Test set: Average loss: 0.657755, Accuracy: 7742/10000 (77.42%)

EPOCH: 6
Loss=0.381800 Batch_id=390 Accuracy=87.11: 100%|██████████| 391/391 [00:56<00:00,  6.97it/s]
  0%|          | 0/391 [00:00<?, ?it/s]
Test set: Average loss: 0.565956, Accuracy: 8100/10000 (81.00%)

EPOCH: 7
Loss=0.362847 Batch_id=390 Accuracy=87.86: 100%|██████████| 391/391 [00:56<00:00,  6.94it/s]
  0%|          | 0/391 [00:00<?, ?it/s]
Test set: Average loss: 0.566716, Accuracy: 8065/10000 (80.65%)

EPOCH: 8
Loss=0.214901 Batch_id=390 Accuracy=93.51: 100%|██████████| 391/391 [00:56<00:00,  6.93it/s]
  0%|          | 0/391 [00:00<?, ?it/s]
Test set: Average loss: 0.317638, Accuracy: 8922/10000 (89.22%)

EPOCH: 9
Loss=0.159078 Batch_id=390 Accuracy=95.52: 100%|██████████| 391/391 [00:56<00:00,  6.95it/s]
  0%|          | 0/391 [00:00<?, ?it/s]
Test set: Average loss: 0.304946, Accuracy: 8941/10000 (89.41%)

EPOCH: 10
Loss=0.131759 Batch_id=390 Accuracy=96.54: 100%|██████████| 391/391 [00:56<00:00,  6.94it/s]
  0%|          | 0/391 [00:00<?, ?it/s]
Test set: Average loss: 0.303746, Accuracy: 8955/10000 (89.55%)

EPOCH: 11
Loss=0.109258 Batch_id=390 Accuracy=97.28: 100%|██████████| 391/391 [00:56<00:00,  6.94it/s]
  0%|          | 0/391 [00:00<?, ?it/s]
Test set: Average loss: 0.305116, Accuracy: 8982/10000 (89.82%)

EPOCH: 12
Loss=0.090592 Batch_id=390 Accuracy=97.91: 100%|██████████| 391/391 [00:56<00:00,  6.95it/s]
  0%|          | 0/391 [00:00<?, ?it/s]
Test set: Average loss: 0.302767, Accuracy: 8975/10000 (89.75%)

EPOCH: 13
Loss=0.073969 Batch_id=390 Accuracy=98.49: 100%|██████████| 391/391 [00:56<00:00,  6.94it/s]
  0%|          | 0/391 [00:00<?, ?it/s]
Test set: Average loss: 0.298591, Accuracy: 8985/10000 (89.85%)

EPOCH: 14
Loss=0.057936 Batch_id=390 Accuracy=99.02: 100%|██████████| 391/391 [00:56<00:00,  6.93it/s]
  0%|          | 0/391 [00:00<?, ?it/s]
Test set: Average loss: 0.308093, Accuracy: 8974/10000 (89.74%)

EPOCH: 15
Loss=0.048438 Batch_id=390 Accuracy=99.30: 100%|██████████| 391/391 [00:56<00:00,  6.91it/s]
  0%|          | 0/391 [00:00<?, ?it/s]
Test set: Average loss: 0.327482, Accuracy: 8932/10000 (89.32%)

EPOCH: 16
Loss=0.035581 Batch_id=390 Accuracy=99.63: 100%|██████████| 391/391 [00:56<00:00,  6.91it/s]
  0%|          | 0/391 [00:00<?, ?it/s]
Test set: Average loss: 0.299198, Accuracy: 9010/10000 (90.10%)

EPOCH: 17
Loss=0.031671 Batch_id=390 Accuracy=99.73: 100%|██████████| 391/391 [00:56<00:00,  6.92it/s]
  0%|          | 0/391 [00:00<?, ?it/s]
Test set: Average loss: 0.291311, Accuracy: 9030/10000 (90.30%)

EPOCH: 18
Loss=0.029998 Batch_id=390 Accuracy=99.75: 100%|██████████| 391/391 [00:56<00:00,  6.93it/s]
  0%|          | 0/391 [00:00<?, ?it/s]
Test set: Average loss: 0.293858, Accuracy: 9014/10000 (90.14%)

EPOCH: 19
Loss=0.028431 Batch_id=390 Accuracy=99.79: 100%|██████████| 391/391 [00:56<00:00,  6.96it/s]
  0%|          | 0/391 [00:00<?, ?it/s]
Test set: Average loss: 0.302664, Accuracy: 9014/10000 (90.14%)

EPOCH: 20
Loss=0.027815 Batch_id=390 Accuracy=99.81: 100%|██████████| 391/391 [00:56<00:00,  6.96it/s]
  0%|          | 0/391 [00:00<?, ?it/s]
Test set: Average loss: 0.294929, Accuracy: 9024/10000 (90.24%)

EPOCH: 21
Loss=0.026659 Batch_id=390 Accuracy=99.84: 100%|██████████| 391/391 [00:56<00:00,  6.94it/s]
  0%|          | 0/391 [00:00<?, ?it/s]
Test set: Average loss: 0.291975, Accuracy: 9021/10000 (90.21%)

EPOCH: 22
Loss=0.026115 Batch_id=390 Accuracy=99.85: 100%|██████████| 391/391 [00:56<00:00,  6.96it/s]
  0%|          | 0/391 [00:00<?, ?it/s]
Test set: Average loss: 0.293583, Accuracy: 9028/10000 (90.28%)

EPOCH: 23
Loss=0.025522 Batch_id=390 Accuracy=99.86: 100%|██████████| 391/391 [00:56<00:00,  6.94it/s]
  0%|          | 0/391 [00:00<?, ?it/s]
Test set: Average loss: 0.297595, Accuracy: 9027/10000 (90.27%)

EPOCH: 24
Loss=0.024930 Batch_id=390 Accuracy=99.87: 100%|██████████| 391/391 [00:56<00:00,  6.95it/s]

Test set: Average loss: 0.296456, Accuracy: 9032/10000 (90.32%)
